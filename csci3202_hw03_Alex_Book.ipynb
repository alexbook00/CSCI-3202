{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Spring 2020\n",
    "# Assignment 3\n",
    "# Due:  Wednesday 4 March 2020 by 11:59 PM\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name: Alex Book\n",
    "\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some things that might be useful**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "from scipy import stats\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1 (35 points):  Playing \"intelligent\" Tic-Tac-Toe\n",
    "\n",
    "<img src=\"https://www.cookieshq.co.uk/images/2016/06/01/tic-tac-toe.png\" width=\"150\"/>\n",
    "\n",
    "<a id='p2a'></a>\n",
    "\n",
    "### (1a)   Defining the Tic-Tac-Toe class structure\n",
    "\n",
    "Fill in this class structure for Tic-Tac-Toe using what we did during class as a guide.\n",
    "* `moves` is a list of tuples to represent which moves are available. Recall that we are using matrix notation for this, where the upper-left corner of the board, for example, is represented at (1,1).\n",
    "* `result(self, move, state)` returns a ***hypothetical*** resulting `State` object if `move` is made when the game is in the current `state`\n",
    "* `compute_utility(self, move, state)` calculates the utility of `state` that would result if `move` is made when the game is in the current `state`. This is where you want to check to see if anyone has gotten `nwin` in a row\n",
    "* `game_over(self, state)` - this wasn't a method, but it should be - it's a piece of code we need to execute repeatedly and giving it a name makes clear what task the piece of code performs. Returns `True` if the game in the given `state` has reached a terminal state, and `False` otherwise.\n",
    "* `utility(self, state, player)` also wasn't a method earlier, but also should be.  Returns the utility of the current state if the player is X and $-1 \\cdot$ utility if the player is O.\n",
    "* `display(self)` is a method to display the current game `state`, You get it for free! because this would be super frustrating without it.\n",
    "* `play_game(self, player1, player2)` returns an integer that is the utility of the outcome of the game (+1 if X wins, 0 if draw, -1 if O wins). `player1` and `player2` are functional arguments that we will deal with in parts **2b** and **2d**.\n",
    "\n",
    "Some notes:\n",
    "* Assume X always goes first.\n",
    "* Do **not** hard-code for 3x3 boards.\n",
    "* You may add attributes and methods to these classes as needed for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in as needed.\n",
    "class State:\n",
    "    def __init__(self, moves):\n",
    "        self.to_move = 'X'\n",
    "        self.utility = 0\n",
    "        self.board = {}\n",
    "        self.moves = cp.copy(moves)\n",
    "\n",
    "        \n",
    "class TicTacToe:\n",
    "    \n",
    "    def __init__(self, nrow=3, ncol=3, nwin=3, nexp=0):\n",
    "        self.nrow = nrow\n",
    "        self.ncol = ncol\n",
    "        self.nwin = nwin\n",
    "        moves = [(row, col) for row in range(1, nrow + 1) for col in range(1, ncol + 1)]\n",
    "        self.state = State(moves)\n",
    "        \n",
    "\n",
    "    def result(self, move, state):\n",
    "        '''\n",
    "        What is the hypothetical result of move `move` in state `state` ?\n",
    "        move  = (row, col) tuple where player will put their mark (X or O)\n",
    "        state = a `State` object, to represent whose turn it is and form\n",
    "                the basis for generating a **hypothetical** updated state\n",
    "                that will result from making the given `move`\n",
    "        '''\n",
    "\n",
    "        # Don't do anything if the move isn't a legal one\n",
    "        if move not in state.moves:\n",
    "            return state\n",
    "        # Return a copy of the updated state:\n",
    "        #   compute utility, update the board, remove the move, update whose turn\n",
    "        new_state = cp.deepcopy(state)\n",
    "        new_state.utility = self.compute_utility(move, state)\n",
    "        new_state.board[move] = state.to_move\n",
    "        new_state.moves.remove(move)\n",
    "        new_state.to_move = ('O' if state.to_move == 'X' else 'X')\n",
    "        return new_state\n",
    "    \n",
    "    def compute_utility(self, move, state):\n",
    "        '''\n",
    "        What is the utility of making move `move` in state `state`?\n",
    "        If 'X' wins with this move, return 1;\n",
    "        if 'O' wins return -1;\n",
    "        else return 0.\n",
    "        '''        \n",
    "\n",
    "        row, col = move\n",
    "        player = state.to_move\n",
    "        \n",
    "        # create a hypothetical copy of the board, with 'move' executed\n",
    "        board = cp.deepcopy(state.board)\n",
    "        board[move] = player\n",
    "\n",
    "        # what are all the ways 'player' could with with 'move'?\n",
    "        \n",
    "        # check for row-wise win\n",
    "        in_a_row = 0\n",
    "        for c in range(1,self.ncol+1):\n",
    "            in_a_row += board.get((row,c))==player\n",
    "\n",
    "        # check for column-wise win\n",
    "        in_a_col = 0\n",
    "        for r in range(1,self.nrow+1):\n",
    "            in_a_col += board.get((r,col))==player\n",
    "\n",
    "        # check for NW->SE diagonal win\n",
    "        in_a_diag1 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag1 += board.get((r,col-(row-r)))==player\n",
    "\n",
    "        # check for SW->NE diagonal win\n",
    "        in_a_diag2 = 0\n",
    "        for r in range(row,0,-1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        for r in range(row+1,self.nrow+1):\n",
    "            in_a_diag2 += board.get((r,col+(row-r)))==player\n",
    "        \n",
    "        if self.nwin in [in_a_row, in_a_col, in_a_diag1, in_a_diag2]:\n",
    "            return 1 if player=='X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "    def game_over(self, state):\n",
    "        '''game is over if someone has won (utility!=0) or there\n",
    "        are no more moves left'''\n",
    "\n",
    "        return state.utility!=0 or len(state.moves)==0\n",
    "        \n",
    "           \n",
    "\n",
    "    \n",
    "    def utility(self, state, player):\n",
    "        '''Return the value to player; 1 for win, -1 for loss, 0 otherwise.'''\n",
    "\n",
    "        return state.utility if player=='X' else -state.utility\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "    def display(self):\n",
    "        board = self.state.board\n",
    "        for row in range(1, self.nrow + 1):\n",
    "            for col in range(1, self.ncol + 1):\n",
    "                print(board.get((row, col), '.'), end=' ')\n",
    "            print()\n",
    "        \n",
    "    def play_game(self, player1, player2):\n",
    "        '''Play a game of tic-tac-toe!'''\n",
    "\n",
    "        turn_limit = self.nrow*self.ncol  # limit in case of buggy code\n",
    "        turn = 0\n",
    "        while turn<=turn_limit:\n",
    "            for player in [player1, player2]:\n",
    "                turn += 1\n",
    "                move = player(self)\n",
    "                self.state = self.result(move, self.state)\n",
    "                if self.game_over(self.state):\n",
    "#                     self.display()\n",
    "                    return self.state.utility           \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1b) Define a random player\n",
    "\n",
    "Define a function `random_player` that takes a single argument of the `TicTacToe` class and returns a random move out of the available legal moves in the `state` of the `TicTacToe` game.\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `random_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(game):\n",
    "    '''A player that chooses a legal move at random out of all\n",
    "    available legal moves in Tic-Tac-Toe state argument'''\n",
    "\n",
    "    \n",
    "    possible_actions = game.state.moves\n",
    "    return possible_actions[np.random.randint(low=0, high=len(possible_actions))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1c) What about playing randomly on different-sized boards?\n",
    "\n",
    "What does the long-term win percentage appear to be for the first player in a 4x4 Tic-Tac-Toe tournament, where 4 marks must be connected for a win?  Support your answer using a simulation and printed output, similar to **2b**.\n",
    "\n",
    "**Also:** The win percentage should have changed substantially. Did the decrease in wins turn into more losses for the first player or more draws? Write a few sentences explaining the behavior you observed.  *Hint: think about how the size of the state space has changed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x3\n",
      "Win pct: 0.5879\n",
      "Draw pct: 0.1269\n",
      "Loss pct: 0.2852\n",
      "\n",
      "4x4\n",
      "Win pct: 0.3096\n",
      "Draw pct: 0.4206\n",
      "Loss pct: 0.2698\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "runs = 10000\n",
    "\n",
    "three_results = []\n",
    "print(\"3x3\")\n",
    "for i in range(runs):\n",
    "    ex = TicTacToe(3,3,3)\n",
    "    three_results.append(ex.play_game(random_player, random_player))\n",
    "print(\"Win pct:\", three_results.count(1)/runs)\n",
    "print(\"Draw pct:\", three_results.count(0)/runs)\n",
    "print(\"Loss pct:\", three_results.count(-1)/runs)\n",
    "\n",
    "print()\n",
    "four_results = []\n",
    "print(\"4x4\")\n",
    "for i in range(runs):\n",
    "    ex2 = TicTacToe(4,4,4)\n",
    "    four_results.append(ex2.play_game(random_player, random_player))\n",
    "print(\"Win pct:\", four_results.count(1)/runs)\n",
    "print(\"Draw pct:\", four_results.count(0)/runs)\n",
    "print(\"Loss pct:\", four_results.count(-1)/runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the board size, the lesser the chance is of a player randomly picking the satisfactory number of spaces in a row to win. Therefore the long-term win percentage decreases, mainly in lieu of the long-term draw percentage increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1d) Define an alpha-beta player\n",
    "\n",
    "Alright. Let's finally get serious about our Tic-Tac-Toe game.  No more fooling around!\n",
    "\n",
    "Craft a function called `alphabeta_player` that takes a single argument of a `TicTacToe` class object and returns the minimax move in the `state` of the `TicTacToe` game. As the name implies, this player should be implementing alpha-beta pruning as described in the textbook and lecture.\n",
    "\n",
    "Note that your alpha-beta search for the minimax move should include function definitions for `max_value` and `min_value` (see the aggressively realistic pseudocode from the lecture slides).\n",
    "\n",
    "In your code for the `play_game` method above, make sure that `alphabeta_player` could be a viable input for the `player1` and/or `player2` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "def alphabeta_player(game, expanded = False):\n",
    "    return alphabeta_search(game, expanded)\n",
    "\n",
    "def alphabeta_search(game, expanded):\n",
    "    '''search game approach to find best action, using alpha-beta pruning:\n",
    "    alpha = best (highest) move found so far for Max\n",
    "    beta  = best (lowest) move found so far for Min'''\n",
    "\n",
    "    expanded_count = [0]\n",
    "    \n",
    "    player = 1 if game.state.to_move == 'X' else -1 # X player trying to positively maximize, O player trying to negatively maximize\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state, alpha, beta):\n",
    "        expanded_count[0] += 1\n",
    "        if game.game_over(state):\n",
    "            return (state.utility*player, None)\n",
    "        # start of alpha-beta process\n",
    "        value = -float('inf')\n",
    "        best = None\n",
    "        for move in state.moves:\n",
    "            newValue, _ = min_value(game.result(move, state), alpha, beta)\n",
    "            if newValue > value:\n",
    "                best = move\n",
    "                value = newValue\n",
    "            if value >= beta:\n",
    "                return (value, best)\n",
    "            alpha = max(value, alpha)\n",
    "        return (value, best)\n",
    "\n",
    "    def min_value(state, alpha, beta):\n",
    "        expanded_count[0] += 1\n",
    "        if game.game_over(state):\n",
    "            return (state.utility*player, None)\n",
    "        # start of alpha-beta process\n",
    "        value = float('inf')\n",
    "        best = None\n",
    "        for move in state.moves:\n",
    "            newValue, _ = max_value(game.result(move, state), alpha, beta)\n",
    "            if newValue < value:\n",
    "                best = move\n",
    "                value = newValue\n",
    "            if value <= alpha:\n",
    "                return (value, best)\n",
    "            beta = min(value, beta)\n",
    "        return (value, best)\n",
    "        \n",
    "    # Body of alphabeta_cutoff_search:\n",
    "    alpha = -float('inf')\n",
    "    beta = float('inf')\n",
    "    _, action = max_value(game.state, alpha, beta)\n",
    "    if expanded is True:\n",
    "        return expanded_count[0]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that your alpha-beta player code is working appropriately through the following tests, using a standard 3x3 Tic-Tac-Toe board. Run **only 10 games for each test**, and track the number of wins, draws and losses.\n",
    "\n",
    "1. An alpha-beta player who plays first should never lose to a random player who plays second.\n",
    "2. A random player who plays first should never win to an alpha-beta player who plays second.\n",
    "3. Two alpha-beta players should always draw.\n",
    "\n",
    "**Nota bene:** Test your code with fewer games between the players to start, because the alpha-beta player will require substantially more compute time than the random player.  This is why I only ask for 10 games, which still might take a minute or two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-beta vs. random\n",
      "Win pct: 1.0\n",
      "Draw pct: 0.0\n",
      "Loss pct: 0.0\n",
      "random vs. alpha-beta\n",
      "Win pct: 0.0\n",
      "Draw pct: 0.2\n",
      "Loss pct: 0.8\n",
      "alpha-beta vs. alpha-beta\n",
      "Win pct: 0.0\n",
      "Draw pct: 1.0\n",
      "Loss pct: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "runs = 10\n",
    "\n",
    "one_results = []\n",
    "print(\"alpha-beta vs. random\")\n",
    "for i in range(runs):\n",
    "    ex = TicTacToe(3,3,3)\n",
    "    one_results.append(ex.play_game(alphabeta_player, random_player))\n",
    "print(\"Win pct:\", one_results.count(1)/runs)\n",
    "print(\"Draw pct:\", one_results.count(0)/runs)\n",
    "print(\"Loss pct:\", one_results.count(-1)/runs)\n",
    "\n",
    "two_results = []\n",
    "print(\"random vs. alpha-beta\")\n",
    "for i in range(runs):\n",
    "    ex = TicTacToe(3,3,3)\n",
    "    two_results.append(ex.play_game(random_player, alphabeta_player))\n",
    "print(\"Win pct:\", two_results.count(1)/runs)\n",
    "print(\"Draw pct:\", two_results.count(0)/runs)\n",
    "print(\"Loss pct:\", two_results.count(-1)/runs)\n",
    "\n",
    "three_results = []\n",
    "print(\"alpha-beta vs. alpha-beta\")\n",
    "for i in range(runs):\n",
    "    ex = TicTacToe(3,3,3)\n",
    "    three_results.append(ex.play_game(alphabeta_player, alphabeta_player))\n",
    "print(\"Win pct:\", three_results.count(1)/runs)\n",
    "print(\"Draw pct:\", three_results.count(0)/runs)\n",
    "print(\"Loss pct:\", three_results.count(-1)/runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "### (1e) What has pruning ever done for us?\n",
    "\n",
    "Calculate the number of number of states expanded by the minimax algorithm, with and without pruning, to determine the minimax decision from the initial 3x3 Tic-Tac-Toe board state.  This can be done in many ways, but writing out all the states by hand is **not** one of them (as you will find out!).\n",
    "\n",
    "Write a sentence or two, commenting on the difference in number of nodes expanded by each search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-beta\n",
      "18297\n",
      "minimax\n",
      "549946\n"
     ]
    }
   ],
   "source": [
    "def minimax(game):\n",
    "    '''search game approach to find best action, using alpha-beta pruning:\n",
    "    alpha = best (highest) move found so far for Max\n",
    "    beta  = best (lowest) move found so far for Min'''\n",
    "\n",
    "    expanded_count = [0]\n",
    "    \n",
    "    player = 1 if game.state.to_move == 'X' else -1\n",
    "\n",
    "    # Functions used by alphabeta\n",
    "    def max_value(state):\n",
    "        expanded_count[0] += 1\n",
    "        if game.game_over(state):\n",
    "            return state.utility*player\n",
    "        value = -float('inf')\n",
    "        for move in state.moves:\n",
    "            value = max(value,min_value(game.result(move, state)))\n",
    "        return value\n",
    "\n",
    "    def min_value(state):\n",
    "        expanded_count[0] += 1\n",
    "        if game.game_over(state):\n",
    "            return state.utility*player\n",
    "        value = float('inf')\n",
    "        for move in state.moves:\n",
    "            value = min(value,max_value(game.result(move, state)))\n",
    "        return value\n",
    "        \n",
    "    max_value(game.state)\n",
    "    return expanded_count[0]\n",
    "\n",
    "ex = TicTacToe(3,3,3)\n",
    "\n",
    "print(\"alpha-beta\")\n",
    "print(alphabeta_player(ex, True))\n",
    "\n",
    "print(\"minimax\")\n",
    "print(minimax(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimax has roughly 30 times the number of nodes expanded when compared to alpha-beta pruning, which makes sense, as pruning allows you to effectively \"skip\" nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 2 (30 points):  Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) \n",
    "\n",
    "Suppose you are deciding when to arrive at a party. There is some optimal time to arrive when the loss you feel, as measured by _awkwardness_, is minimized at 0. That is, at some particular time, it is not awkward at all to show up to the party. The awkwardness (loss) increases as you arrive too early or too late relative to this optimal time. What is a suitable loss function, $L(d, x)$, to model this situation? Include definitions for $d$ and $x$, consistent with the examples from this class. Use this loss function this weekend when you go out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(d,x) =  \\begin{cases} \n",
    "      x-d & x > d \\\\\n",
    "      d-x & x \\leq d\n",
    "   \\end{cases} $$\n",
    "   \n",
    "d represents the time of arrival at the party (starting at d=0) and x represents the current state of the party (likely how the attendees would judge your arrival)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2b)\n",
    "\n",
    "Suppose we have a situation where loss is given by the function $L(d, x) = 2(d-x)^2$. Set up, simplify, and evaluate integral(s) for the expected loss, $E_x[L(d, x)]$, where your prior beliefs regarding $x$ follow the distribution $f(x)$ given below. You may assume $f(x)=0$ for values of $x$ outside of the interval $[0, 3]$.\n",
    "\n",
    "$$f(x) =  \\begin{cases} \n",
    "      1/2 & 0 \\leq x <1 \\\\\n",
    "      3/8 & 1 \\leq x <2 \\\\\n",
    "      1/8 & 2 \\leq x \\leq 3 \n",
    "   \\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E_x[L(d, x)] = \\int_{0}^{3} 2(d-x)^2 dx$ \\\n",
    "$E_x[L(d, x)] = \\int_{0}^{1} 2(d-x)^2*\\frac{1}{2} dx$ + $\\int_{1}^{2} 2(d-x)^2*\\frac{3}{8} dx$ + $\\int_{2}^{3} 2(d-x)^2*\\frac{1}{8} dx$ \\\n",
    "$E_x[L(d, x)] = \\int_{0}^{1} (d-x)^2 dx$ + $\\frac{3}{4}\\int_{1}^{2} (d-x)^2 dx$ + $\\frac{1}{4}\\int_{2}^{3} (d-x)^2 dx$ \\\n",
    "$E_x[L(d, x)] = \\int_{0}^{1} (d^2-2dx+x^2) dx$ + $\\frac{3}{4}\\int_{1}^{2} (d^2-2dx+x^2) dx$ + $\\frac{1}{4}\\int_{2}^{3} (d^2-2dx+x^2) dx$ \\\n",
    "$E_x[L(d, x)] = (d^2x-dx^2+\\frac{1}{3}x^3) \\Big|_{0}^{1}$ + $\\frac{3}{4}(d^2x-dx^2+\\frac{1}{3}x^3) \\Big|_{1}^{2}$ + $\\frac{1}{4}(d^2x-dx^2+\\frac{1}{3}x^3) \\Big|_{2}^{3}$ \\\n",
    "$E_x[L(d, x)] = (d^2-d+\\frac{1}{3})+\\frac{3}{4}( (2d^2-4d+\\frac{8}{3})-(d^2-d+\\frac{1}{3}) )+\\frac{1}{4}( (3d^2-9d+9)-(2d^2-4d+\\frac{8}{3}) )$ \\\n",
    "$E_x[L(d, x)] = (d^2-d+\\frac{1}{3})+\\frac{3}{4}(d^2-3d+\\frac{7}{3})+\\frac{1}{4}(d^2-5d+\\frac{19}{3})$ \\\n",
    "$E_x[L(d, x)] = (d^2-d+\\frac{1}{3})+(\\frac{3}{4}d^2-\\frac{9}{4}d+\\frac{7}{4})+(\\frac{1}{4}d^2-\\frac{5}{4}d+\\frac{19}{12})$ \\\n",
    "$E_x[L(d, x)] = 2d^2-\\frac{9}{2}d+\\frac{11}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c) \n",
    "\n",
    "Suppose our expected loss is represented by the function $E_x[(L(d,x)]=(2-d)^2+2$, and our prior beliefs regarding $x$ are given by the distribution $f(x)$ from part b.\n",
    "\n",
    "- Calculate Bayes' Decision, $d_{Bayes}$.\n",
    "\n",
    "- Calculate the Expected Value of Including Uncertainty, EVIU. Suppose that if we ignore uncertainty, our best guess for what decision to make is the median of $x$ (under our prior $f(x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d_{Bayes} = 2$ \\\n",
    "$d_{iu}=median(x)=1$ because the interval [0,1] contains half the volume/value of the probability distribution function \\\n",
    "\\\n",
    "$EVIU = \\int_{0}^{3} (L(d_{iu},x)-L(d_{Bayes},x))f(x)dx$ \\\n",
    "$EVIU = \\int_{0}^{3} (((2-1)^2+2) - ((2-2)^2+2))f(x)dx$ \\\n",
    "$EVIU = \\int_{0}^{3} (3-2)f(x)dx$ \\\n",
    "$EVIU = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Problem 3 (35 points): Maximizing some objective function with a Genetic Algorithm\n",
    "\n",
    "Suppose we are trying to figure out a cookie recipe, but can't quite remember how much of each ingredient we need.\n",
    "\n",
    "So we want to maximize the following objective function corresponding to how close we are to this recipe:\n",
    "\n",
    "* 3/4 cup granulated sugar (36 tsp)\n",
    "* 3/4 cup packed brown sugar  (36 tsp)\n",
    "* 1 cup butter (48 tsp)\n",
    "* 1 teaspoon vanilla (1 tsp)\n",
    "* 1 egg\n",
    "* 2 1/4 cups flour (108 tsp)\n",
    "* 1 teaspoon baking soda (1 tsp)\n",
    "* 1/2 teaspoon salt (0.5 tsp)\n",
    "* 1 package (12 ounces) chocolate chips (2 cups) (96 tsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [64,32,16,8,4,2,1,.5]\n",
    "\n",
    "# use binary to represent recipes in order to have a more \"orderly\" process of mutation as shown by an example in class\n",
    "\n",
    "target = np.array([[0,1,0,0,1,0,0,0],\n",
    "          [0,1,0,0,1,0,0,0],\n",
    "          [0,1,1,0,0,0,0,0],\n",
    "          [0,0,0,0,0,0,1,0],\n",
    "          [0,0,0,0,0,0,1,0],\n",
    "          [1,1,0,1,1,0,0,0],\n",
    "          [0,0,0,0,0,0,1,0],\n",
    "          [0,0,0,0,0,0,0,1],\n",
    "          [1,1,0,0,0,0,0,0]])\n",
    "\n",
    "# target = [36, 36, 48, 1, 1, 108, 1, 0.5, 96]\n",
    "\n",
    "target = np.reshape(target,72) # make target recipe a 1d array for more easily checking the fitness of each recipe in a given iteration/generation\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example starting state for a member of our population might look like: $state = [30, 30, 40, 1, 0, 100, 0.5, 0.5, 100]$\n",
    "\n",
    "### (3a) \n",
    "\n",
    "Write an objective function `def recipe_success(state)` that takes a single argument state, and returns the objective function value (fitness) of the state. The objective function should be maximized when a state reaches the target. You could for example define the fitness score of a particular state based on how far away each entry is from the target recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns number of bits that are correct (maximum of 72)\n",
    "def recipe_success(state):\n",
    "    # Your code here.\n",
    "    ret = 0\n",
    "    for i in range(len(state)):\n",
    "        if state[i] == target[i]:\n",
    "            ret+=1\n",
    "    return ret\n",
    "\n",
    "# a = np.random.randint(0,2,72)\n",
    "# print(a)\n",
    "# print(recipe_success(a))\n",
    "# print(recipe_success(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) \n",
    "\n",
    "Using our in class notebook \"CSCI3202_GeneticAlgorithm.ipynb\" as your guide, write a genetic algorithm that starts with a population of 10 randomly generated \"recipes/states/members\" and uses the objective function you wrote in **(3a)** to hopefully hit the target after a certain number of generations. \n",
    "\n",
    "Key components of your code:\n",
    "- Generate the initial population randomly from numbers between 0 and 108 (half step intervals might be helpful since the recipe requires 1/2 tsp salt)\n",
    "- Allow for mutations in your population with an overall probability of mutation set to p = 0.1\n",
    "- Choose 2 \"parents\" in the generation of each \"child\"\n",
    "- Choose a random split point at which to combine the two \"parents\"\n",
    "- Run the algorithm for 200 iterations (\"generations\"). Do you hit your target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not reach goal state after 200 iterations.\n",
      "Best recipe: [37, 37, 48, 1, 1, 108, 65, 0.5, 96]\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "class problem:\n",
    "    \n",
    "    def __init__(self, initial_population, objective_function, mutation_probability, fitness_goal):\n",
    "        '''\n",
    "        initial_population = list of lists; each sub-list is a dna string for a population member\n",
    "        objective_function = objective function to maximize\n",
    "        mutation_probability = probability that any given child has a mutation\n",
    "        fitness_goal = fitness goal to achieve (stopping criterion, once member reaches this)\n",
    "        '''\n",
    "        self.population = initial_population\n",
    "        self.initial_population = initial_population\n",
    "        self.objective_function = objective_function\n",
    "        self.p_mutate = mutation_probability\n",
    "        self.n_pop = len(initial_population)\n",
    "        self.n_dna = len(initial_population[0])\n",
    "        self.fitness_goal = fitness_goal\n",
    "\n",
    "    def fitness(self):\n",
    "        '''\n",
    "        calculate each population member's probability of being selected for\n",
    "        reproduction based on performance on objective function\n",
    "        '''\n",
    "        performance = []\n",
    "        for k in range(self.n_pop):\n",
    "            performance.append(self.objective_function(self.population[k]))\n",
    "        return performance # returns list of the number of correct bits of each recipe in a given population/generation\n",
    "        \n",
    "    def reproduce(self, parent1, parent2):\n",
    "        # last DNA snippet from parent1\n",
    "        split = np.random.randint(low=1, high=self.n_dna)\n",
    "        child = np.append(parent1[:split],parent2[split:])\n",
    "        return child\n",
    "\n",
    "    def mutate(self, child):\n",
    "        # which gene to mutate?\n",
    "        # will randomly flip one bit of a given individual\n",
    "        gene = np.random.randint(low=0, high=self.n_dna) # picks the bit to flip\n",
    "        child[gene] = 0 if child[gene]==1 else 1 # flips the bit\n",
    "        return child\n",
    "\n",
    "def genetic_algorithm(problem, n_iter):\n",
    "    \n",
    "    for t in range(n_iter):\n",
    "        \n",
    "        new_generation = []\n",
    "        # select best half of population for reproduction\n",
    "        performance = problem.fitness() # array of fitness levels of all members of current/parent population\n",
    "        half = int(problem.n_pop/2) # number of parents that will have the possibility of reproducing\n",
    "        parent_indices = np.argsort(performance)[-half:] # array of the indices of the top half of parents\n",
    "        \n",
    "        for k in range(problem.n_pop):\n",
    "            \n",
    "            indices_of_parents = np.random.choice(parent_indices, size=2, replace=False) # indices of the two parents randomly chosen from the possibilities\n",
    "            parent1, parent2 = problem.population[indices_of_parents[0]], problem.population[indices_of_parents[1]] # gets the parents with the given indices\n",
    "            \n",
    "            # reproduce\n",
    "            child = problem.reproduce(parent1, parent2)\n",
    "            \n",
    "            # mutate\n",
    "            l_mutate = np.random.choice([True, False], p=[problem.p_mutate, 1-problem.p_mutate])\n",
    "            if l_mutate:\n",
    "                child = problem.mutate(child)\n",
    "            \n",
    "            # add to new generation\n",
    "            new_generation.append(child)\n",
    "        \n",
    "        # set problem.population = new generation\n",
    "        problem.population = new_generation\n",
    "        \n",
    "        # exit criterion check\n",
    "        # array of fitness levels of all members of new population\n",
    "        performance = [problem.objective_function(member) for member in problem.population]\n",
    "        \n",
    "        best_member = max(zip(performance, problem.population), key = lambda x: x[0])\n",
    "        \n",
    "        # checks if the best member matches the target recipe\n",
    "        if best_member[0] >= problem.fitness_goal:\n",
    "            return True,best_member,t # returns True, the most successful recipe, and the number of iterations taken to reach the goal\n",
    "\n",
    "    return False,best_member,t # returns False, the most successful recipe, and the number of iterations attempted\n",
    "\n",
    "initial_pop = []\n",
    "for i in range(10): # initial population size of 10\n",
    "    initial_pop.append(np.random.choice(range(2),size=72)) # 9 ingredients of 8 bits each, 72 bits total for each individual\n",
    "\n",
    "p = problem(initial_pop, recipe_success, .1, 72) # 10% chance of mutation, maximum fitness level of 72 (if recipe matches the target)\n",
    "success, best_recipe, iterations = genetic_algorithm(p, 200)\n",
    "\n",
    "# make the recipe easily readable by changing from binary to decimal\n",
    "best_recipe_reshaped = np.reshape(best_recipe[1],(9,8))\n",
    "true_recipe = []\n",
    "for i in best_recipe_reshaped:\n",
    "    temp = int(\"\".join(str(x) for x in i[0:7]), 2)\n",
    "    if i[7] == 1:\n",
    "        temp += .5\n",
    "    true_recipe.append(temp)\n",
    "\n",
    "if success == True:\n",
    "    print(\"Reached goal state in\",iterations+1,\"iterations.\")\n",
    "    \n",
    "elif success == False:\n",
    "    print(\"Did not reach goal state after\",iterations+1,\"iterations.\")\n",
    "    \n",
    "print(\"Best recipe:\",true_recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the randomness of my genetic algorithm \"gets lucky,\" under 200 iterations is possible, but it's not likely (seen from my testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3c)\n",
    "\n",
    "Report the following:\n",
    "- How many generations did it take to hit the goal?\n",
    "- If you change the initial population size to 100, does that change the number of generations it takes to achieve the goal recipe?\n",
    "- If you change the probability of mutation to 0.2, does that affect the number of generations it takes to achieve the goal recipe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***NOTE***: The number of iterations will vary from test to test due to the randomness of the initial population, breeding, and mutation.\n",
      "\n",
      "It took 437 iterations to hit the goal with an initial population size of 10.\n",
      "\n",
      "With the initial population as size 100, it now takes 39 iterations to hit the goal. So increasing the size of the initial population decreases the number of iterations needed to hit the goal.\n",
      "\n",
      "With a probability of mutation of .2 instead of the original .1, and using the same initial population as the test directly above, it takes 36 iterations to hit the goal. So increasing the probability of mutation doesn't noticeably change the number of iterations needed to hit the goal.\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "\n",
    "print(\"***NOTE***: The number of iterations will vary from test to test due to the randomness of the initial population, breeding, and mutation.\")\n",
    "print()\n",
    "\n",
    "initial_pop = []\n",
    "for i in range(10):\n",
    "    initial_pop.append(np.random.choice(range(2),size=72))\n",
    "\n",
    "p = problem(initial_pop, recipe_success, .1, 72)\n",
    "success, best_recipe, iterations = genetic_algorithm(p, 1000)\n",
    "\n",
    "best_recipe_reshaped = np.reshape(best_recipe[1],(9,8))\n",
    "true_recipe = []\n",
    "for i in best_recipe_reshaped:\n",
    "    temp = int(\"\".join(str(x) for x in i[0:7]), 2)\n",
    "    if i[7] == 1:\n",
    "        temp += .5\n",
    "    true_recipe.append(temp)\n",
    "    \n",
    "print(\"It took\",iterations,\"iterations to hit the goal with an initial population size of 10.\")\n",
    "print()\n",
    "\n",
    "########\n",
    "\n",
    "initial_pop = []\n",
    "for i in range(100):\n",
    "    initial_pop.append(np.random.choice(range(2),size=72))\n",
    "\n",
    "p = problem(initial_pop, recipe_success, .1, 72)\n",
    "success, best_recipe, iterations = genetic_algorithm(p, 1000)\n",
    "\n",
    "best_recipe_reshaped = np.reshape(best_recipe[1],(9,8))\n",
    "true_recipe = []\n",
    "for i in best_recipe_reshaped:\n",
    "    temp = int(\"\".join(str(x) for x in i[0:7]), 2)\n",
    "    if i[7] == 1:\n",
    "        temp += .5\n",
    "    true_recipe.append(temp)\n",
    "\n",
    "print(\"With the initial population as size 100, it now takes\",iterations,\"iterations to hit the goal. So increasing the size of the initial population decreases the number of iterations needed to hit the goal.\")\n",
    "print()\n",
    "\n",
    "########\n",
    "\n",
    "p = problem(initial_pop, recipe_success, .2, 72)\n",
    "success, best_recipe, iterations = genetic_algorithm(p, 1000)\n",
    "\n",
    "best_recipe_reshaped = np.reshape(best_recipe[1],(9,8))\n",
    "true_recipe = []\n",
    "for i in best_recipe_reshaped:\n",
    "    temp = int(\"\".join(str(x) for x in i[0:7]), 2)\n",
    "    if i[7] == 1:\n",
    "        temp += .5\n",
    "    true_recipe.append(temp)\n",
    "    \n",
    "print(\"With a probability of mutation of .2 instead of the original .1, and using the same initial population as the test directly above, it takes\",iterations,\"iterations to hit the goal. So increasing the probability of mutation doesn't noticeably change the number of iterations needed to hit the goal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE***: The number of iterations will vary from test to test due to the randomness of the initial population, breeding, and mutation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
